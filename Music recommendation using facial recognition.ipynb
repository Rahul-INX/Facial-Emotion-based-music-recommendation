{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tempfile\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from pygame import mixer\n",
    "\n",
    "\n",
    "# Initialize the pipeline for image classification\n",
    "pipe = pipeline(\"image-classification\", model=\"facial_emotions_image_detection\")\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Flag to control the loop\n",
    "predict_emotions = False\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Press 'C' To Capture Image\", frame)\n",
    "    \n",
    "    # Press 'c' to capture a temporary photo and predict emotions\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        predict_emotions = True\n",
    "    \n",
    "    if predict_emotions:\n",
    "        # Detect faces in the frame\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        if faces is not None and len(faces) > 0:\n",
    "            \n",
    "            # Consider first detected face for simplicity\n",
    "            x, y, w, h = faces[0]\n",
    "\n",
    "            # Crop the face from the frame\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Convert to PIL image\n",
    "            face_pil = Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Resize to 224x224 pixels\n",
    "            face_resized = face_pil.resize((224, 224))\n",
    "            # Convert to grayscale (if needed by the model)\n",
    "            face_gray = face_resized.convert('L')\n",
    "            \n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                temp_image_path = os.path.join(temp_dir, \"temp_photo.jpg\")\n",
    "                # Save the processed image\n",
    "                face_gray.save(temp_image_path)\n",
    "                \n",
    "                # Predict emotions from the temporary image\n",
    "                emotions = pipe(temp_image_path)\n",
    "                \n",
    "                # Iterate through the predicted emotions\n",
    "                for emotion in emotions:\n",
    "                    emotion_label = emotion['label']\n",
    "                    # Create a path for the emotion label folder\n",
    "                    folder_path = os.path.join( emotion_label)\n",
    "                    \n",
    "                    # Check if the folder exists, if not, create it\n",
    "                    if not os.path.exists(folder_path):\n",
    "                        os.makedirs(folder_path)\n",
    "                        print(f\"Folder created for: {emotion_label}\")\n",
    "\n",
    "                # Print predicted emotions\n",
    "                print(\"Predicted Emotions:\", emotions)\n",
    "                \n",
    "                if emotions:\n",
    "                    dominant_emotion = emotions[0].get('label')\n",
    "                    print(f\"Emotion: {dominant_emotion}\\nScore: {emotions[0].get('score')}\")\n",
    "                \n",
    "                face_gray                \n",
    "            break  # Exit loop after processing the face\n",
    "    \n",
    "    # Press 'q' to quit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"progream uit by user\")\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8799a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to play selected MP3 file\n",
    "def play_audio(file_path):\n",
    "    mixer.init()\n",
    "    mixer.music.load(file_path)\n",
    "    mixer.music.play()\n",
    "\n",
    "# Function to stop playing audio\n",
    "def stop_audio():\n",
    "    mixer.music.stop()\n",
    "\n",
    "# Create a folder for the dominant emotion if it doesn't exist\n",
    "emotion_folder = os.path.join(os.getcwd(), dominant_emotion)\n",
    "if not os.path.exists(emotion_folder):\n",
    "    print(f\"No audio files found for {dominant_emotion} emotion.\")\n",
    "else:\n",
    "    # print(f\"Emotion detected: {dominant_emotion}\")\n",
    "\n",
    "    # Create Tkinter window\n",
    "    root = tk.Tk()\n",
    "    root.title(f\"Emotion: {dominant_emotion}\")\n",
    "\n",
    "    # Create listbox to display MP3 files\n",
    "    listbox = tk.Listbox(root, width=50)\n",
    "    listbox.pack(pady=10)\n",
    "\n",
    "    # Populate listbox with MP3 files in emotion folder\n",
    "    for file in os.listdir(emotion_folder):\n",
    "        if file.endswith(\".mp3\"):\n",
    "            listbox.insert(tk.END, file)\n",
    "\n",
    "    # Function to play selected MP3 file\n",
    "    def play_selected():\n",
    "        selection = listbox.curselection()\n",
    "        if selection:\n",
    "            selected_file = listbox.get(selection[0])\n",
    "            audio_path = os.path.join(emotion_folder, selected_file)\n",
    "            play_audio(audio_path)\n",
    "\n",
    "    # Function to handle window close event\n",
    "    def on_close():\n",
    "        stop_audio()\n",
    "        root.destroy()\n",
    "\n",
    "    # Create play button\n",
    "    play_button = ttk.Button(root, text=\"Play\", command=play_selected)\n",
    "    play_button.pack(pady=10)\n",
    "\n",
    "    # Bind window close event to stop playing audio\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", on_close)\n",
    "\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
